{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdergOqk-nHf"
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SkfF3sqL-raW",
    "outputId": "adfeb2c3-b354-44b1-a5a3-8d465c4c98ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3lzMmqYR55Ch"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.init import kaiming_uniform_, xavier_uniform_\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kVh2EsuYP2hF"
   },
   "source": [
    "## Abstract classes for custom datasets, main classifier and early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kY-Ll0iP_pyf"
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    \"\"\"An abstract class representing the training dataset\"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        X (dataframe): set of predictors\n",
    "        y (series): corresponding target variable \n",
    "        \"\"\"\n",
    "        self.X = X.astype('float32')\n",
    "        self.y = y.astype('float32').values.reshape((len(y), 1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    \"\"\"An abstract class representing the unseen test dataset\"\"\"\n",
    "    def __init__(self, X):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (dataframe): set of predictors\n",
    "        \"\"\"\n",
    "        self.X = X.astype('float32')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    \"\"\"A multilayer perceptron designed for binary classification problems\"\"\"\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        n_inputs (int): number of features in training set\n",
    "        n_hidden (int): number of nodes in hidden layers\n",
    "        n_outputs (int): number of outputs (e.g.: 1 for binary classification)\n",
    "        \"\"\"\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "\n",
    "        # the combination of Relu activation and He Uniform weight initialization comes \n",
    "        # a lonng way to overcome the problem of vanishing gradients when training \n",
    "        # deep neural network models\n",
    "        self.h1 = nn.Linear(n_inputs, n_hidden)\n",
    "        kaiming_uniform_(self.h1.weight, nonlinearity='relu')\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.b1 = nn.BatchNorm1d(n_hidden)\n",
    "\n",
    "        self.h2 = nn.Linear(n_hidden, n_hidden)\n",
    "        kaiming_uniform_(self.h2.weight, nonlinearity='relu')\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.d2 = nn.Dropout(p=0.1)\n",
    "\n",
    "        self.h3 = nn.Linear(n_hidden, n_outputs)\n",
    "        xavier_uniform_(self.h3.weight)\n",
    "        self.a3 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        out = self.a1(self.h1(inp))\n",
    "        out = self.b1(out)\n",
    "        out = self.a2(self.h2(out))\n",
    "        out = self.d2(out)\n",
    "        out = self.a3(self.h3(out))\n",
    "        return out\n",
    "\n",
    "class EarlyStopping():\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): how long to wait after last time validation loss improved.\n",
    "                            default: 7\n",
    "            verbose (bool): if True, print a message for each validation loss improvement. \n",
    "                            default: False\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model, checkpoint):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, checkpoint)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, checkpoint)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, checkpoint):\n",
    "        \"\"\"Save model when validation loss decreases\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f'Val loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        torch.save(checkpoint, checkpoint_save_path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1uyinkDbQZnI"
   },
   "source": [
    "## Utility functions to prepare datasets, train and evaluate model, infer predictions and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wvliq38PJxNK"
   },
   "outputs": [],
   "source": [
    "def prepare_train_data(path, batch_size, val_size, does_scale=True):\n",
    "    \"\"\"\n",
    "    Split data into train and validation sets, scale them approriately and \n",
    "    convert them into DataLoader iterators\n",
    "        :param path (string): file location of the training data set\n",
    "        :param batch_size (int): batch size for data loader\n",
    "        :param val_size (float): proportion of data set to include in validation split\n",
    "        :param does_scale (bool): whether to normalize the data or not\n",
    "        :return: train data loader (iterator), validation data loader (iterator), \n",
    "                training set of predictors (dataframe), training set of target variable (series),\n",
    "                validation set of predictors (dataframe), validation set of target variable (series),\n",
    "                scaler based on training data (estimator)\n",
    "    \"\"\"\n",
    "    data = pd.read_pickle(path)\n",
    "    X = data.drop('label', axis=1)\n",
    "    y = data['label']\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=val_size, random_state=42)\n",
    "\n",
    "    # when using a neural network, it’s advisable to normalize numeric predictors \n",
    "    # so that values with large magnitudes don’t overwhelm small values; plus, we \n",
    "    # should normalize val data using the training set values \n",
    "    if does_scale: \n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    train_ds = TrainDataset(X_train, y_train)\n",
    "    val_ds = TrainDataset(X_val, y_val)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_dl, val_dl, X_train, X_val, y_train, y_val, scaler\n",
    "\n",
    "\n",
    "def prepare_test_data(path, scaler):\n",
    "    \"\"\"\n",
    "    Scale unseen data according to training set (if specified) and convert it into\n",
    "    a data loader to be fed into the network later\n",
    "        :param path (string): file location of the unseen test data\n",
    "        :param scaler (estimator): either None or the normalizer based on training values\n",
    "    \"\"\"\n",
    "    X = pd.read_pickle(path)\n",
    "\n",
    "    if scaler:\n",
    "        X_test = scaler.transform(X)\n",
    "    test_ds = TestDataset(X_test)\n",
    "    test_dl = DataLoader(test_ds, batch_size=1)\n",
    "    \n",
    "    return test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "eZlI_9XNwXfN"
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, loss_fn, train_dl):\n",
    "    \"\"\"\n",
    "    Model training with backpropogation\n",
    "        :param model (nn.Module): pre-defined model\n",
    "        :param optimizer (nn.optim): pre-defined optimizer\n",
    "        :param loss_fn: criterion/metrics to optimize on \n",
    "        :param train_dl (iterator): data loader of training set\n",
    "        :return: epoch loss (float)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    for inputs, targets in train_dl:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        preds = model(inputs)\n",
    "        loss = loss_fn(preds, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(train_dl)\n",
    "\n",
    "\n",
    "def evaluate_model(model, loss_fn, val_dl):\n",
    "    \"\"\"\n",
    "    Evaluate model on data that wasn't used for training without backprogation\n",
    "    :param model (nn.Module): pre-defined model\n",
    "    :param loss_fn: criterion used for to optimze on \n",
    "    :param val_dl (iterator): data loader of validation/test set\n",
    "    :return: epoch loss (float)  \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_dl:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            preds = model(inputs)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            assert loss.requires_grad is False\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(val_dl)\n",
    "\n",
    "\n",
    "def infer_preds(model, dl, is_train=False):\n",
    "    \"\"\"\n",
    "    Infer probability estimates of positive class \n",
    "        :param model (nn.Module): trained model\n",
    "        :param dl (iterator): data loader of the dataset to be inferred\n",
    "        :param is_train (bool): whether this data has been used for training \n",
    "        :return: predicted values (list)\n",
    "    \"\"\"\n",
    "    pred_ls = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if not is_train:\n",
    "            for inputs in dl: \n",
    "                inputs = inputs.to(device)\n",
    "                preds = model(inputs)\n",
    "                pred_ls.append(preds.cpu().numpy())\n",
    "            pred_ls = [i.squeeze().tolist() for i in pred_ls]\n",
    "        else:\n",
    "            for inputs, _ in dl:\n",
    "                inputs = inputs.to(device)\n",
    "                preds = model(inputs)\n",
    "                pred_ls = np.append(pred_ls, preds.cpu().numpy())\n",
    "    \n",
    "    return pred_ls\n",
    "\n",
    "\n",
    "def process_loop(n_epochs, model, optimizer, loss_fn, train_dl, val_dl):\n",
    "    \"\"\"\n",
    "    Run entire training loop which comprises of multiple epochs\n",
    "        :param n_epochs (int): number of maximum epochs to train through\n",
    "        :param model (nn.Module): pre-defined model\n",
    "        :param optimizer (nn.optim): pre-defined optimizer\n",
    "        :param loss_fn: criterion for optimizer to iterate on\n",
    "        :param train_dl (iterator): training data loader\n",
    "        :param val_dl (iterator): validation data loader\n",
    "        :return: train losses of all epochs (list of floats), \n",
    "                validation losses of all epochs (list of floats)\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStopping(patience=7, verbose=True)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train_model(model, optimizer, loss_fn, train_dl)\n",
    "        val_loss = evaluate_model(model, loss_fn, val_dl)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': round(train_loss, 5),\n",
    "            'val_loss': round(val_loss, 5)\n",
    "        }\n",
    "\n",
    "        early_stopping(val_loss, model, checkpoint)\n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "        \n",
    "        print('Epoch: {} | Time: {}m {}s'.format(epoch, epoch_mins, epoch_secs))\n",
    "        print('\\tTrain loss: {}'.format(round(train_loss, 5)))\n",
    "        print('\\tVal loss: {}'.format(round(val_loss, 5)))\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-pF6iWMbQqDX"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Count the number of trainable parameters in the model\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    \"\"\"Calculate time to train each epoch\"\"\"\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "def load_checkpoint(model, opt, path):\n",
    "    \"\"\"Load model from its most recent checkpoint. Note that input model \n",
    "    & optimizer should be pre-defined.  This routine only updates their states.\n",
    "        :param model (nn.Module): pre-defined model \n",
    "        :param opt (nn.optim): pre-defined optimizer\n",
    "        :param path (string): where the checkpoint was saved\n",
    "        :return: updated model (nn.Module), updated optimizer (nn.optim), \n",
    "                epoch number where training was left off (int), training loss (float),\n",
    "                validation loss (float)\n",
    "    \"\"\"\n",
    "    start_epoch = 0\n",
    "    if os.path.isfile(path):\n",
    "        print(\"=> loading checkpoint '{}'\".format(path))\n",
    "        checkpoint = torch.load(path)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        train_loss = checkpoint['train_loss']\n",
    "        val_loss = checkpoint['val_loss']\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                .format(path, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(path))\n",
    "\n",
    "    return model, opt, start_epoch, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aP-liZxv5EDu"
   },
   "outputs": [],
   "source": [
    "def get_youden_thres(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Compute the threshold that separates postive and negative classes based on Youden's J statistic.\n",
    "    J = sensitivity + specificity - 1 = TPR + (1 - FPR) - 1 = TPR - FPR.\n",
    "      :param y_true: true labels\n",
    "      :param y_prob: probability estimates of positive class\n",
    "      :return: separating threshold based on Youden's index\n",
    "    \"\"\"\n",
    "    fpr, tpr, thres = roc_curve(y_true, y_prob)\n",
    "    i = np.arange(len(tpr))\n",
    "    roc = pd.DataFrame({'fpr': pd.Series(fpr, index=i),\n",
    "                        'tpr': pd.Series(tpr, index=i),\n",
    "                        '1-fpr': pd.Series(1 - fpr, index=i),\n",
    "                        'youden': pd.Series(tpr - fpr, index=i),\n",
    "                        'threshold': pd.Series(thres, index=i)})\n",
    "    opt_pt = roc.iloc[roc['youden'].idxmax(), :]\n",
    "    return opt_pt['threshold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_EHBTOOuXD3X"
   },
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3s68ISxdwaGR"
   },
   "outputs": [],
   "source": [
    "train_path = '/content/gdrive/My Drive/KalapaCreditScoringChallenge/data/intermediate/train2.pkl'\n",
    "save_dir = '/content/gdrive/My Drive/KalapaCreditScoringChallenge/models'\n",
    "model_save_path = os.path.join(save_dir, 'MLP.pt')\n",
    "checkpoint_save_path = os.path.join(save_dir, 'MLP-checkpoint.tar')\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "n_outputs = 1  # binary classification\n",
    "\n",
    "# hyperparameters that should be selected through trials and errors\n",
    "N_EPOCHS = 100 \n",
    "BATCH_SIZE = 128\n",
    "N_HIDDEN = 50\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1GmRTIKPXM5s",
    "outputId": "31afc762-a33c-42c9-896b-b4c683467d35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 12001 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "train_dl, val_dl, X_train, X_val, y_train, y_val, scaler = prepare_train_data(train_path, \n",
    "                                                                              BATCH_SIZE, \n",
    "                                                                              0.20)\n",
    "\n",
    "n_inputs = X_train.shape[1]\n",
    "model = BinaryClassifier(n_inputs, N_HIDDEN, n_outputs)\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "print('The model has {} trainable parameters'.format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IqKNH1nOqQvy",
    "outputId": "e1deacd6-c67c-4eea-9afa-215512bb8b7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss decreased (inf --> 0.618667).  Saving model ...\n",
      "Epoch: 0 | Time: 0m 0s\n",
      "\tTrain loss: 0.66639\n",
      "\tVal loss: 0.61867\n",
      "Val loss decreased (0.618667 --> 0.604297).  Saving model ...\n",
      "Epoch: 1 | Time: 0m 0s\n",
      "\tTrain loss: 0.62376\n",
      "\tVal loss: 0.6043\n",
      "Val loss decreased (0.604297 --> 0.596213).  Saving model ...\n",
      "Epoch: 2 | Time: 0m 0s\n",
      "\tTrain loss: 0.60766\n",
      "\tVal loss: 0.59621\n",
      "Val loss decreased (0.596213 --> 0.591124).  Saving model ...\n",
      "Epoch: 3 | Time: 0m 0s\n",
      "\tTrain loss: 0.6007\n",
      "\tVal loss: 0.59112\n",
      "Val loss decreased (0.591124 --> 0.587887).  Saving model ...\n",
      "Epoch: 4 | Time: 0m 0s\n",
      "\tTrain loss: 0.59435\n",
      "\tVal loss: 0.58789\n",
      "Val loss decreased (0.587887 --> 0.584306).  Saving model ...\n",
      "Epoch: 5 | Time: 0m 0s\n",
      "\tTrain loss: 0.58882\n",
      "\tVal loss: 0.58431\n",
      "Val loss decreased (0.584306 --> 0.582414).  Saving model ...\n",
      "Epoch: 6 | Time: 0m 0s\n",
      "\tTrain loss: 0.5872\n",
      "\tVal loss: 0.58241\n",
      "Val loss decreased (0.582414 --> 0.580087).  Saving model ...\n",
      "Epoch: 7 | Time: 0m 0s\n",
      "\tTrain loss: 0.58325\n",
      "\tVal loss: 0.58009\n",
      "Val loss decreased (0.580087 --> 0.578327).  Saving model ...\n",
      "Epoch: 8 | Time: 0m 0s\n",
      "\tTrain loss: 0.58183\n",
      "\tVal loss: 0.57833\n",
      "Val loss decreased (0.578327 --> 0.576434).  Saving model ...\n",
      "Epoch: 9 | Time: 0m 0s\n",
      "\tTrain loss: 0.57967\n",
      "\tVal loss: 0.57643\n",
      "Val loss decreased (0.576434 --> 0.575391).  Saving model ...\n",
      "Epoch: 10 | Time: 0m 0s\n",
      "\tTrain loss: 0.57761\n",
      "\tVal loss: 0.57539\n",
      "Val loss decreased (0.575391 --> 0.573987).  Saving model ...\n",
      "Epoch: 11 | Time: 0m 0s\n",
      "\tTrain loss: 0.57552\n",
      "\tVal loss: 0.57399\n",
      "Val loss decreased (0.573987 --> 0.572966).  Saving model ...\n",
      "Epoch: 12 | Time: 0m 0s\n",
      "\tTrain loss: 0.57448\n",
      "\tVal loss: 0.57297\n",
      "Val loss decreased (0.572966 --> 0.572217).  Saving model ...\n",
      "Epoch: 13 | Time: 0m 0s\n",
      "\tTrain loss: 0.57314\n",
      "\tVal loss: 0.57222\n",
      "Val loss decreased (0.572217 --> 0.571542).  Saving model ...\n",
      "Epoch: 14 | Time: 0m 0s\n",
      "\tTrain loss: 0.57257\n",
      "\tVal loss: 0.57154\n",
      "Val loss decreased (0.571542 --> 0.570799).  Saving model ...\n",
      "Epoch: 15 | Time: 0m 0s\n",
      "\tTrain loss: 0.57108\n",
      "\tVal loss: 0.5708\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 16 | Time: 0m 0s\n",
      "\tTrain loss: 0.57102\n",
      "\tVal loss: 0.57131\n",
      "Val loss decreased (0.570799 --> 0.570606).  Saving model ...\n",
      "Epoch: 17 | Time: 0m 0s\n",
      "\tTrain loss: 0.5687\n",
      "\tVal loss: 0.57061\n",
      "Val loss decreased (0.570606 --> 0.569674).  Saving model ...\n",
      "Epoch: 18 | Time: 0m 0s\n",
      "\tTrain loss: 0.56865\n",
      "\tVal loss: 0.56967\n",
      "Val loss decreased (0.569674 --> 0.568308).  Saving model ...\n",
      "Epoch: 19 | Time: 0m 0s\n",
      "\tTrain loss: 0.56709\n",
      "\tVal loss: 0.56831\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 20 | Time: 0m 0s\n",
      "\tTrain loss: 0.56695\n",
      "\tVal loss: 0.56837\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch: 21 | Time: 0m 0s\n",
      "\tTrain loss: 0.56575\n",
      "\tVal loss: 0.56853\n",
      "Val loss decreased (0.568308 --> 0.567492).  Saving model ...\n",
      "Epoch: 22 | Time: 0m 0s\n",
      "\tTrain loss: 0.56638\n",
      "\tVal loss: 0.56749\n",
      "Val loss decreased (0.567492 --> 0.566896).  Saving model ...\n",
      "Epoch: 23 | Time: 0m 0s\n",
      "\tTrain loss: 0.56513\n",
      "\tVal loss: 0.5669\n",
      "Val loss decreased (0.566896 --> 0.566673).  Saving model ...\n",
      "Epoch: 24 | Time: 0m 0s\n",
      "\tTrain loss: 0.56417\n",
      "\tVal loss: 0.56667\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 25 | Time: 0m 0s\n",
      "\tTrain loss: 0.56347\n",
      "\tVal loss: 0.56696\n",
      "Val loss decreased (0.566673 --> 0.566496).  Saving model ...\n",
      "Epoch: 26 | Time: 0m 0s\n",
      "\tTrain loss: 0.56362\n",
      "\tVal loss: 0.5665\n",
      "Val loss decreased (0.566496 --> 0.566099).  Saving model ...\n",
      "Epoch: 27 | Time: 0m 0s\n",
      "\tTrain loss: 0.56291\n",
      "\tVal loss: 0.5661\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 28 | Time: 0m 0s\n",
      "\tTrain loss: 0.56232\n",
      "\tVal loss: 0.56627\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch: 29 | Time: 0m 0s\n",
      "\tTrain loss: 0.56291\n",
      "\tVal loss: 0.56658\n",
      "Val loss decreased (0.566099 --> 0.565231).  Saving model ...\n",
      "Epoch: 30 | Time: 0m 0s\n",
      "\tTrain loss: 0.56157\n",
      "\tVal loss: 0.56523\n",
      "Val loss decreased (0.565231 --> 0.564992).  Saving model ...\n",
      "Epoch: 31 | Time: 0m 0s\n",
      "\tTrain loss: 0.56205\n",
      "\tVal loss: 0.56499\n",
      "Val loss decreased (0.564992 --> 0.564791).  Saving model ...\n",
      "Epoch: 32 | Time: 0m 0s\n",
      "\tTrain loss: 0.56124\n",
      "\tVal loss: 0.56479\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 33 | Time: 0m 0s\n",
      "\tTrain loss: 0.56037\n",
      "\tVal loss: 0.56561\n",
      "Val loss decreased (0.564791 --> 0.564777).  Saving model ...\n",
      "Epoch: 34 | Time: 0m 0s\n",
      "\tTrain loss: 0.56102\n",
      "\tVal loss: 0.56478\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 35 | Time: 0m 0s\n",
      "\tTrain loss: 0.56003\n",
      "\tVal loss: 0.56497\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch: 36 | Time: 0m 0s\n",
      "\tTrain loss: 0.55956\n",
      "\tVal loss: 0.56729\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch: 37 | Time: 0m 0s\n",
      "\tTrain loss: 0.56013\n",
      "\tVal loss: 0.56596\n",
      "Val loss decreased (0.564777 --> 0.564764).  Saving model ...\n",
      "Epoch: 38 | Time: 0m 0s\n",
      "\tTrain loss: 0.55907\n",
      "\tVal loss: 0.56476\n",
      "Val loss decreased (0.564764 --> 0.564116).  Saving model ...\n",
      "Epoch: 39 | Time: 0m 0s\n",
      "\tTrain loss: 0.55918\n",
      "\tVal loss: 0.56412\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 40 | Time: 0m 0s\n",
      "\tTrain loss: 0.55885\n",
      "\tVal loss: 0.56442\n",
      "Val loss decreased (0.564116 --> 0.564045).  Saving model ...\n",
      "Epoch: 41 | Time: 0m 0s\n",
      "\tTrain loss: 0.55897\n",
      "\tVal loss: 0.56405\n",
      "Val loss decreased (0.564045 --> 0.563683).  Saving model ...\n",
      "Epoch: 42 | Time: 0m 0s\n",
      "\tTrain loss: 0.55849\n",
      "\tVal loss: 0.56368\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch: 43 | Time: 0m 0s\n",
      "\tTrain loss: 0.55846\n",
      "\tVal loss: 0.56447\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch: 44 | Time: 0m 0s\n",
      "\tTrain loss: 0.55737\n",
      "\tVal loss: 0.56459\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch: 45 | Time: 0m 0s\n",
      "\tTrain loss: 0.55797\n",
      "\tVal loss: 0.56473\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch: 46 | Time: 0m 0s\n",
      "\tTrain loss: 0.5572\n",
      "\tVal loss: 0.56428\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch: 47 | Time: 0m 0s\n",
      "\tTrain loss: 0.55754\n",
      "\tVal loss: 0.56406\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch: 48 | Time: 0m 0s\n",
      "\tTrain loss: 0.55713\n",
      "\tVal loss: 0.56411\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = process_loop(n_epochs=N_EPOCHS, \n",
    "                                       optimizer=optimizer,\n",
    "                                       model=model, \n",
    "                                       loss_fn=nn.BCELoss(),\n",
    "                                       train_dl=train_dl,\n",
    "                                       val_dl=val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "Lo2Bul9A24QV",
    "outputId": "4670be82-9671-4c63-c30c-5d6da9014db4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, marker='', label='Train')\n",
    "plt.plot(val_losses, linestyle='dashed', label='Validation')\n",
    "plt.title('Train vs Validation Performance')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5VuyfB6Xo2k"
   },
   "source": [
    "## Inference process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "E89ZdCJ8dnnz"
   },
   "outputs": [],
   "source": [
    "save_dir = '/content/gdrive/My Drive/KalapaCreditScoringChallenge/results'\n",
    "X_test_path = '/content/gdrive/My Drive/KalapaCreditScoringChallenge/data/intermediate/test1.pkl'\n",
    "test_ids = pd.read_csv('/content/gdrive/My Drive/KalapaCreditScoringChallenge/data/raw/test.csv', low_memory=False)['id']\n",
    "\n",
    "test_dl = prepare_test_data(X_test_path, scaler)\n",
    "test_preds = infer_preds(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "80S77VBwzi9V"
   },
   "outputs": [],
   "source": [
    "submission_df_binary = pd.concat([test_ids, \n",
    "                                  pd.DataFrame(np.rint(test_preds), columns=['label'])], \n",
    "                                 axis=1)\n",
    "submission_df_binary.to_csv(os.path.join(save_dir, 'MLP_binary.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QMq8rPRg5La_"
   },
   "outputs": [],
   "source": [
    "train_preds = infer_preds(model, train_dl, is_train=True)\n",
    "train_youden_thres = get_youden_thres(y_train.astype('category'), train_preds)\n",
    "test_youden_binary = np.where(test_preds >= train_youden_thres, 1, 0)\n",
    "\n",
    "submission_df_youden = pd.concat([test_ids, \n",
    "                                  pd.DataFrame(test_youden_binary, columns=['label'])], \n",
    "                                 axis=1)\n",
    "submission_df_youden.to_csv(os.path.join(save_dir, 'MLP_youden.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1uyinkDbQZnI"
   ],
   "name": "build_neural_net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
